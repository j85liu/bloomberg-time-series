{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01714262",
   "metadata": {},
   "source": [
    "## Test Temporal Fusion Transformers V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee53c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 169\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rsi\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Generate data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_synthetic_financial_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Visualize the generated data\u001b[39;00m\n\u001b[1;32m    172\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 118\u001b[0m, in \u001b[0;36mgenerate_synthetic_financial_data\u001b[0;34m(n_samples, start_date)\u001b[0m\n\u001b[1;32m    116\u001b[0m volume_noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, price \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m, n_samples)\n\u001b[1;32m    117\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m volume_base \u001b[38;5;241m+\u001b[39m volume_trend \u001b[38;5;241m+\u001b[39m volume_noise\n\u001b[0;32m--> 118\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Add volume momentum\u001b[39;00m\n\u001b[1;32m    121\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_ma7\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/finance/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:145\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our TFT implementation\n",
    "# Assuming you saved the TFT code in a file called temporal_fusion_transformer.py\n",
    "from models.tft_v3 import TemporalFusionTransformer\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ====================== 1. Generate Synthetic Financial Data ======================\n",
    "\n",
    "def generate_synthetic_financial_data(n_samples=2000, start_date=\"2020-01-01\"):\n",
    "    \"\"\"Generate synthetic stock price data with market regimes, trends, seasonality, and events.\"\"\"\n",
    "    dates = pd.date_range(start=start_date, periods=n_samples)\n",
    "    t = np.arange(n_samples)\n",
    "    \n",
    "    # Generate market regimes (bull, bear, sideways)\n",
    "    regime_changes = np.sort(np.random.choice(range(100, n_samples-100), size=6, replace=False))\n",
    "    regimes = np.zeros(n_samples)\n",
    "    \n",
    "    current_regime = np.random.choice([0, 1, 2])  # 0=bull, 1=bear, 2=sideways\n",
    "    for i in range(len(regime_changes) + 1):\n",
    "        start_idx = 0 if i == 0 else regime_changes[i-1]\n",
    "        end_idx = n_samples if i == len(regime_changes) else regime_changes[i]\n",
    "        regimes[start_idx:end_idx] = current_regime\n",
    "        current_regime = (current_regime + np.random.choice([1, 2])) % 3\n",
    "    \n",
    "    # Base price with trend dependent on regime\n",
    "    price = 100 * np.ones(n_samples)\n",
    "    for i in range(1, n_samples):\n",
    "        if regimes[i] == 0:  # Bull\n",
    "            drift = 0.08  # Positive trend\n",
    "            vol = 1.0\n",
    "        elif regimes[i] == 1:  # Bear\n",
    "            drift = -0.05  # Negative trend\n",
    "            vol = 1.8\n",
    "        else:  # Sideways\n",
    "            drift = 0.01\n",
    "            vol = 0.8\n",
    "            \n",
    "        price[i] = price[i-1] * (1 + np.random.normal(drift/252, vol/np.sqrt(252)))\n",
    "    \n",
    "    # Add weekly seasonality (5-day pattern)\n",
    "    weekly = 0.005 * price * np.sin(2 * np.pi * t / 5)\n",
    "    \n",
    "    # Add monthly seasonality\n",
    "    monthly = 0.02 * price * np.sin(2 * np.pi * t / 30)\n",
    "    \n",
    "    # Add quarterly seasonality\n",
    "    quarterly = 0.05 * price * np.sin(2 * np.pi * t / 90)\n",
    "    \n",
    "    # Random events (occasional price jumps with mean reversion)\n",
    "    events = np.zeros(n_samples)\n",
    "    event_indices = np.random.choice(range(n_samples), size=int(n_samples * 0.03), replace=False)\n",
    "    for idx in event_indices:\n",
    "        jump_size = np.random.normal(0, 0.03)\n",
    "        events[idx] = jump_size * price[idx]\n",
    "        # Add mean reversion after jumps\n",
    "        reversion_length = min(7, n_samples - idx - 1)\n",
    "        reversion = np.linspace(jump_size, 0, reversion_length+2)[1:-1]\n",
    "        events[idx:idx+reversion_length] += price[idx] * reversion\n",
    "    \n",
    "    # Daily noise\n",
    "    noise = np.random.normal(0, 0.01, n_samples) * price\n",
    "    \n",
    "    # Combine components\n",
    "    price = price + weekly + monthly + quarterly + events + noise\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'price': price,\n",
    "        'regime': regimes,\n",
    "        'day_of_week': dates.dayofweek,\n",
    "        'day_of_month': dates.day,\n",
    "        'month': dates.month,\n",
    "        'is_quarter_end': dates.is_quarter_end.astype(int),\n",
    "        'is_month_end': dates.is_month_end.astype(int),\n",
    "        'year': dates.year\n",
    "    })\n",
    "    \n",
    "    # Add technical indicators\n",
    "    df['ma7'] = df['price'].rolling(window=7).mean()\n",
    "    df['ma30'] = df['price'].rolling(window=30).mean()\n",
    "    df['std7'] = df['price'].rolling(window=7).std()\n",
    "    df['std30'] = df['price'].rolling(window=30).std()\n",
    "    df['rsi'] = compute_rsi(df['price'], 14)\n",
    "    \n",
    "    # Add price momentum features\n",
    "    for window in [1, 3, 7, 14, 30]:\n",
    "        df[f'return_{window}d'] = df['price'].pct_change(window)\n",
    "    \n",
    "    # Add Bollinger Bands\n",
    "    df['bb_upper'] = df['ma30'] + 2 * df['std30']\n",
    "    df['bb_lower'] = df['ma30'] - 2 * df['std30']\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['ma30']\n",
    "    \n",
    "    # Add synthetic trading volume (correlated with volatility)\n",
    "    volume_base = price * (1 + 0.5 * df['std7'].fillna(0) / df['price'])\n",
    "    volume_trend = 0.1 * t\n",
    "    volume_noise = np.random.normal(0, price * 0.1, n_samples)\n",
    "    df['volume'] = volume_base + volume_trend + volume_noise\n",
    "    # Make sure there are no NaN or inf values before converting to int\n",
    "    df['volume'] = df['volume'].fillna(0).replace([np.inf, -np.inf], 0).astype(int)\n",
    "\n",
    "    # Add volume momentum (after making sure volume has no NaNs)\n",
    "    df['volume_ma7'] = df['volume'].rolling(window=7).mean()\n",
    "    df['volume_ratio'] = df['volume'] / df['volume_ma7'].replace(0, 1)  # Avoid division by zero\n",
    "    \n",
    "    # Add synthetic sentiment data\n",
    "    sentiment_base = 0.5 + 0.2 * np.sin(2 * np.pi * t / 120)\n",
    "    # Make sentiment react to price changes\n",
    "    sentiment_price_effect = 0.3 * df['return_7d'].fillna(0)\n",
    "    sentiment_noise = np.random.normal(0, 0.1, n_samples)\n",
    "    df['sentiment'] = np.clip(sentiment_base + sentiment_price_effect + sentiment_noise, 0, 1)\n",
    "    \n",
    "    # Add cyclical encoding for time features\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # Fill NaN values\n",
    "    df = df.fillna(method='bfill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compute_rsi(prices, window=14):\n",
    "    \"\"\"Compute Relative Strength Index.\"\"\"\n",
    "    deltas = np.diff(prices)\n",
    "    seed = deltas[:window+1]\n",
    "    up = seed[seed >= 0].sum()/window\n",
    "    down = -seed[seed < 0].sum()/window\n",
    "    rs = up/down\n",
    "    rsi = np.zeros_like(prices)\n",
    "    rsi[:window] = 100. - 100./(1. + rs)\n",
    "    \n",
    "    for i in range(window, len(prices)):\n",
    "        delta = deltas[i-1]\n",
    "        if delta > 0:\n",
    "            upval = delta\n",
    "            downval = 0\n",
    "        else:\n",
    "            upval = 0\n",
    "            downval = -delta\n",
    "            \n",
    "        up = (up * (window - 1) + upval) / window\n",
    "        down = (down * (window - 1) + downval) / window\n",
    "        rs = up/down\n",
    "        rsi[i] = 100. - 100./(1. + rs)\n",
    "        \n",
    "    return rsi\n",
    "\n",
    "# Generate data\n",
    "df = generate_synthetic_financial_data(n_samples=2000)\n",
    "\n",
    "# Visualize the generated data\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(df['date'], df['price'])\n",
    "plt.title('Synthetic Stock Price')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(df['date'], df['volume'])\n",
    "plt.title('Synthetic Trading Volume')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(df['date'], df['sentiment'])\n",
    "plt.title('Synthetic Market Sentiment')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show technical indicators\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df['date'], df['price'], label='Price')\n",
    "plt.plot(df['date'], df['ma7'], label='7-day MA')\n",
    "plt.plot(df['date'], df['ma30'], label='30-day MA')\n",
    "plt.title('Price and Moving Averages')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(df['date'], df['rsi'], color='purple')\n",
    "plt.axhline(y=70, color='r', linestyle='-', alpha=0.3)\n",
    "plt.axhline(y=30, color='g', linestyle='-', alpha=0.3)\n",
    "plt.title('RSI (14)')\n",
    "plt.ylabel('RSI')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ====================== 2. Prepare Data for TFT ======================\n",
    "\n",
    "# Setting up the forecast parameters\n",
    "backcast_length = 30  # Number of past time steps to use\n",
    "forecast_horizon = 7  # Number of future time steps to predict\n",
    "\n",
    "def prepare_tft_data(df, backcast_length, forecast_horizon):\n",
    "    \"\"\"Prepare data for TFT model with enhanced features\"\"\"\n",
    "    data_df = df.copy()\n",
    "    \n",
    "    # Feature columns with new additions\n",
    "    price_cols = ['price']\n",
    "    \n",
    "    technical_cols = [\n",
    "        'ma7', 'ma30', 'std7', 'std30', 'rsi', \n",
    "        'bb_upper', 'bb_lower', 'bb_width',\n",
    "        'return_1d', 'return_3d', 'return_7d', 'return_14d', 'return_30d'\n",
    "    ]\n",
    "    \n",
    "    volume_cols = ['volume', 'volume_ma7', 'volume_ratio']\n",
    "    sentiment_cols = ['sentiment']\n",
    "    \n",
    "    # Enhanced time features using cyclical encoding\n",
    "    calendar_cols = [\n",
    "        'day_of_week_sin', 'day_of_week_cos', \n",
    "        'month_sin', 'month_cos',\n",
    "        'is_quarter_end', 'is_month_end'\n",
    "    ]\n",
    "    \n",
    "    # Rest of your preparation function remains the same...\n",
    "    \n",
    "    # Normalize the data using StandardScaler\n",
    "    scalers = {}\n",
    "    for col in price_cols + technical_cols + volume_cols + sentiment_cols:\n",
    "        scaler = StandardScaler()\n",
    "        data_df[f'{col}_scaled'] = scaler.fit_transform(data_df[[col]])\n",
    "        scalers[col] = scaler\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    calendar_cols_encoded = []\n",
    "    for col in calendar_cols:\n",
    "        if col in ['day_of_week', 'month']:\n",
    "            dummies = pd.get_dummies(data_df[col], prefix=col)\n",
    "            data_df = pd.concat([data_df, dummies], axis=1)\n",
    "            calendar_cols_encoded.extend(dummies.columns)\n",
    "        else:\n",
    "            calendar_cols_encoded.append(col)\n",
    "    \n",
    "    # Define dataset\n",
    "    price_cols_scaled = [f'{col}_scaled' for col in price_cols]\n",
    "    technical_cols_scaled = [f'{col}_scaled' for col in technical_cols]\n",
    "    volume_cols_scaled = [f'{col}_scaled' for col in volume_cols]\n",
    "    sentiment_cols_scaled = [f'{col}_scaled' for col in sentiment_cols]\n",
    "    \n",
    "    # Features for the model\n",
    "    static_features = []  # No static features for this example\n",
    "    \n",
    "    # Past inputs\n",
    "    encoder_time_varying_known = calendar_cols_encoded  # Calendar features we know for the past\n",
    "    encoder_time_varying_unknown = price_cols_scaled + technical_cols_scaled + volume_cols_scaled + sentiment_cols_scaled\n",
    "    \n",
    "    # Future inputs\n",
    "    decoder_time_varying_known = calendar_cols_encoded  # Calendar features we know for the future \n",
    "    decoder_time_varying_unknown = []  # We don't know future price, volume, etc.\n",
    "    \n",
    "    # Prepare the dataset - creating windows\n",
    "    samples = len(data_df) - backcast_length - forecast_horizon + 1\n",
    "    \n",
    "    # Initialize arrays directly with proper shapes\n",
    "    # For encoder inputs\n",
    "    enc_known = np.zeros((samples, backcast_length, len(encoder_time_varying_known))) if encoder_time_varying_known else []\n",
    "    enc_unknown = np.zeros((samples, backcast_length, len(encoder_time_varying_unknown))) if encoder_time_varying_unknown else []\n",
    "    \n",
    "    # For decoder inputs\n",
    "    dec_known = np.zeros((samples, forecast_horizon, len(decoder_time_varying_known))) if decoder_time_varying_known else []\n",
    "    \n",
    "    # For target\n",
    "    targets = np.zeros((samples, forecast_horizon))\n",
    "    \n",
    "    # Fill the arrays\n",
    "    for i in range(samples):\n",
    "        if encoder_time_varying_known:\n",
    "            enc_known[i] = data_df.iloc[i:i+backcast_length][encoder_time_varying_known].values\n",
    "            \n",
    "        if encoder_time_varying_unknown:\n",
    "            enc_unknown[i] = data_df.iloc[i:i+backcast_length][encoder_time_varying_unknown].values\n",
    "            \n",
    "        if decoder_time_varying_known:\n",
    "            dec_known[i] = data_df.iloc[i+backcast_length:i+backcast_length+forecast_horizon][decoder_time_varying_known].values\n",
    "            \n",
    "        targets[i] = data_df.iloc[i+backcast_length:i+backcast_length+forecast_horizon]['price_scaled'].values\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_static = []  # Empty since we have no static features\n",
    "    \n",
    "    # Convert encoder inputs to tensors\n",
    "    X_encoder = []\n",
    "    if len(enc_known) > 0:\n",
    "        X_encoder.append(torch.FloatTensor(enc_known))\n",
    "    if len(enc_unknown) > 0:\n",
    "        X_encoder.append(torch.FloatTensor(enc_unknown))\n",
    "    \n",
    "    # Convert decoder inputs to tensors\n",
    "    X_decoder = []\n",
    "    if len(dec_known) > 0:\n",
    "        X_decoder.append(torch.FloatTensor(dec_known))\n",
    "    \n",
    "    # Convert target to tensor\n",
    "    y = torch.FloatTensor(targets)\n",
    "    \n",
    "    return X_static, X_encoder, X_decoder, y, scalers\n",
    "\n",
    "# Prepare the data\n",
    "X_static, X_encoder, X_decoder, y, scalers = prepare_tft_data(df, backcast_length, forecast_horizon)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(y))\n",
    "\n",
    "# Handle X_static based on whether it's empty\n",
    "if X_static:\n",
    "    X_static_train, X_static_test = [x[:train_size] for x in X_static], [x[train_size:] for x in X_static]\n",
    "else:\n",
    "    X_static_train, X_static_test = [], []\n",
    "\n",
    "X_encoder_train = [x[:train_size] for x in X_encoder]\n",
    "X_encoder_test = [x[train_size:] for x in X_encoder]\n",
    "X_decoder_train = [x[:train_size] for x in X_decoder]\n",
    "X_decoder_test = [x[train_size:] for x in X_decoder]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Train data shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {y_test.shape}\")\n",
    "\n",
    "# Display data shapes\n",
    "for i, tensor in enumerate(X_encoder_train):\n",
    "    print(f\"Encoder input {i} shape: {tensor.shape}\")\n",
    "for i, tensor in enumerate(X_decoder_train):\n",
    "    print(f\"Decoder input {i} shape: {tensor.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6e918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
