{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c4f267",
   "metadata": {},
   "source": [
    "## Testing LSTM on VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3078c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Testing on VIX Dataset\n",
    "# This script loads VIX data, trains an LSTM model, and evaluates performance\n",
    "\n",
    "# Import necessary libraries for training\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from models.lstm import LSTMModel\n",
    "\n",
    "# Load VIX data\n",
    "print(\"Loading VIX data...\")\n",
    "vix_data_path = \"data/real/cboe_data/VIX_History.csv\"\n",
    "df = pd.read_csv(vix_data_path)\n",
    "\n",
    "# Data preprocessing\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['DATE'].iloc[0]} to {df['DATE'].iloc[-1]}\")\n",
    "\n",
    "# Convert DATE column to datetime and set as index\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "\n",
    "# Sort by date to ensure chronological order (oldest to newest)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nVIX Data Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remove any rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Data shape after removing NaN: {df.shape}\")\n",
    "\n",
    "# Use CLOSE price as our target variable (VIX closing values)\n",
    "# VIX represents implied volatility, so we're predicting future volatility levels\n",
    "target_column = 'CLOSE'\n",
    "print(f\"\\nUsing {target_column} as target variable\")\n",
    "print(f\"Target range: {df[target_column].min():.2f} to {df[target_column].max():.2f}\")\n",
    "\n",
    "# Create sequences function\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Create input sequences and targets for time series prediction\n",
    "    \n",
    "    Args:\n",
    "        data: 1D array of time series values\n",
    "        seq_length: Length of input sequences (lookback window)\n",
    "    \n",
    "    Returns:\n",
    "        X: Input sequences [num_sequences, seq_length, 1]\n",
    "        y: Target values [num_sequences, 1]\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Use seq_length previous values to predict next value\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Parameters - keep same as original code\n",
    "sequence_length = 30  # Use 30 days of VIX history to predict the next day\n",
    "lookforward = 7      # Note: Currently predicting 1 day ahead (can be extended to multi-step)\n",
    "test_ratio = 0.2     # 20% test split (most recent data for testing)\n",
    "\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"Sequence length: {sequence_length} days\")\n",
    "print(f\"Test ratio: {test_ratio}\")\n",
    "\n",
    "# Prepare the target data\n",
    "vix_values = df[target_column].values.reshape(-1, 1)  # Reshape for scaler\n",
    "\n",
    "# Scale the data using MinMaxScaler (normalizes to 0-1 range)\n",
    "print(\"\\nScaling data...\")\n",
    "lstm_scaler = MinMaxScaler()\n",
    "lstm_values_scaled = lstm_scaler.fit_transform(vix_values)\n",
    "\n",
    "print(f\"Scaled data range: {lstm_values_scaled.min():.4f} to {lstm_values_scaled.max():.4f}\")\n",
    "\n",
    "# Create sequences for LSTM input\n",
    "print(\"Creating sequences...\")\n",
    "lstm_X, lstm_y = create_sequences(lstm_values_scaled.flatten(), sequence_length)\n",
    "\n",
    "print(f\"Total sequences created: {len(lstm_X)}\")\n",
    "print(f\"Input shape: {lstm_X.shape}\")  # [num_sequences, seq_length]\n",
    "print(f\"Target shape: {lstm_y.shape}\")  # [num_sequences]\n",
    "\n",
    "# Split into train and test sets (chronological split - no shuffling for time series)\n",
    "lstm_test_size = int(len(lstm_X) * test_ratio)\n",
    "lstm_train_size = len(lstm_X) - lstm_test_size\n",
    "\n",
    "# Split data chronologically (train on older data, test on recent data)\n",
    "lstm_X_train, lstm_X_test = lstm_X[:lstm_train_size], lstm_X[lstm_train_size:]\n",
    "lstm_y_train, lstm_y_test = lstm_y[:lstm_train_size], lstm_y[lstm_train_size:]\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"Training samples: {len(lstm_X_train)}\")\n",
    "print(f\"Test samples: {len(lstm_X_test)}\")\n",
    "\n",
    "# Convert to PyTorch tensors and add feature dimension\n",
    "lstm_X_train = torch.FloatTensor(lstm_X_train).unsqueeze(-1)  # Add feature dimension\n",
    "lstm_y_train = torch.FloatTensor(lstm_y_train).unsqueeze(-1)  # Add feature dimension\n",
    "lstm_X_test = torch.FloatTensor(lstm_X_test).unsqueeze(-1)    # Add feature dimension\n",
    "lstm_y_test = torch.FloatTensor(lstm_y_test).unsqueeze(-1)    # Add feature dimension\n",
    "\n",
    "print(f\"Final tensor shapes:\")\n",
    "print(f\"X_train: {lstm_X_train.shape}\")  # [num_train, seq_length, 1]\n",
    "print(f\"y_train: {lstm_y_train.shape}\")  # [num_train, 1]\n",
    "print(f\"X_test: {lstm_X_test.shape}\")    # [num_test, seq_length, 1]\n",
    "print(f\"y_test: {lstm_y_test.shape}\")    # [num_test, 1]\n",
    "\n",
    "# Create data loaders for batch processing\n",
    "batch_size = 32\n",
    "lstm_train_dataset = TensorDataset(lstm_X_train, lstm_y_train)\n",
    "lstm_test_dataset = TensorDataset(lstm_X_test, lstm_y_test)\n",
    "lstm_train_loader = DataLoader(lstm_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "lstm_test_loader = DataLoader(lstm_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Created data loaders with batch size: {batch_size}\")\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = 1  # Single feature (VIX close price)\n",
    "hidden_size = 64  # LSTM hidden state size\n",
    "num_layers = 2    # Number of LSTM layers\n",
    "output_size = 1   # Predicting single value (next day VIX)\n",
    "\n",
    "lstm_model = LSTMModel(input_size=input_size, hidden_size=hidden_size, \n",
    "                      num_layers=num_layers, output_size=output_size)\n",
    "lstm_criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"Input size: {input_size}\")\n",
    "print(f\"Hidden size: {hidden_size}\")\n",
    "print(f\"Number of layers: {num_layers}\")\n",
    "print(f\"Output size: {output_size}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in lstm_model.parameters())}\")\n",
    "\n",
    "# Training\n",
    "print(f\"\\nStarting training...\")\n",
    "num_epochs = 50\n",
    "lstm_train_losses = []\n",
    "lstm_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm_model.train()  # Set model to training mode\n",
    "    lstm_running_loss = 0.0\n",
    "    \n",
    "    # Process each batch\n",
    "    for batch_idx, (inputs, targets) in enumerate(lstm_train_loader):\n",
    "        # Forward pass\n",
    "        lstm_outputs = lstm_model(inputs)\n",
    "        lstm_loss = lstm_criterion(lstm_outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        lstm_optimizer.zero_grad()  # Clear gradients\n",
    "        lstm_loss.backward()        # Compute gradients\n",
    "        lstm_optimizer.step()       # Update parameters\n",
    "        \n",
    "        lstm_running_loss += lstm_loss.item()\n",
    "    \n",
    "    # Calculate average loss for this epoch\n",
    "    lstm_avg_loss = lstm_running_loss / len(lstm_train_loader)\n",
    "    lstm_train_losses.append(lstm_avg_loss)\n",
    "    \n",
    "    # Print progress every 5 epochs\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {lstm_avg_loss:.6f}')\n",
    "\n",
    "lstm_training_time = time.time() - lstm_start_time\n",
    "print(f\"Training completed in {lstm_training_time:.2f} seconds\")\n",
    "\n",
    "# Evaluation\n",
    "print(f\"\\nEvaluating model...\")\n",
    "lstm_model.eval()  # Set model to evaluation mode\n",
    "lstm_predictions = []\n",
    "lstm_actuals = []\n",
    "lstm_inference_start = time.time()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    for inputs, targets in lstm_test_loader:\n",
    "        outputs = lstm_model(inputs)\n",
    "        lstm_predictions.append(outputs.numpy())\n",
    "        lstm_actuals.append(targets.numpy())\n",
    "    \n",
    "    # Concatenate all batch predictions\n",
    "    lstm_predictions = np.concatenate(lstm_predictions)\n",
    "    lstm_actuals = np.concatenate(lstm_actuals)\n",
    "    \n",
    "    # Inverse transform to original VIX scale\n",
    "    lstm_predictions = lstm_scaler.inverse_transform(lstm_predictions)\n",
    "    lstm_actuals = lstm_scaler.inverse_transform(lstm_actuals)\n",
    "\n",
    "lstm_inference_time = time.time() - lstm_inference_start\n",
    "\n",
    "# Calculate performance metrics\n",
    "lstm_mse = mean_squared_error(lstm_actuals, lstm_predictions)\n",
    "lstm_rmse = np.sqrt(lstm_mse)\n",
    "lstm_mae = mean_absolute_error(lstm_actuals, lstm_predictions)\n",
    "\n",
    "# Calculate additional financial metrics for VIX prediction\n",
    "mape = np.mean(np.abs((lstm_actuals - lstm_predictions) / lstm_actuals)) * 100\n",
    "direction_accuracy = np.mean((np.diff(lstm_actuals.flatten()) > 0) == \n",
    "                           (np.diff(lstm_predictions.flatten()) > 0)) * 100\n",
    "\n",
    "print(f\"\\nLSTM Performance Metrics on VIX:\")\n",
    "print(f\"Test MSE: {lstm_mse:.4f}\")\n",
    "print(f\"Test RMSE: {lstm_rmse:.4f}\")\n",
    "print(f\"Test MAE: {lstm_mae:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"Direction Accuracy: {direction_accuracy:.2f}%\")\n",
    "print(f\"Inference time: {lstm_inference_time:.4f} seconds\")\n",
    "\n",
    "# Create date index for predictions\n",
    "# Get the corresponding dates for test predictions\n",
    "test_start_idx = sequence_length + lstm_train_size\n",
    "test_end_idx = test_start_idx + len(lstm_predictions)\n",
    "lstm_pred_dates = df.index[test_start_idx:test_end_idx]\n",
    "\n",
    "print(f\"Prediction period: {lstm_pred_dates[0]} to {lstm_pred_dates[-1]}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Training loss over epochs\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(lstm_train_losses, 'b-', linewidth=2)\n",
    "plt.title('LSTM Training Loss on VIX Data', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Predictions vs actuals (test period only)\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(lstm_actuals.flatten(), label='Actual VIX', color='black', linewidth=2)\n",
    "plt.plot(lstm_predictions.flatten(), label='LSTM Predictions', color='red', linewidth=2)\n",
    "plt.title('LSTM Predictions vs Actual VIX (Test Period)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('VIX Level')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Predictions with dates (test period)\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(lstm_pred_dates, lstm_actuals.flatten(), label='Actual VIX', \n",
    "         color='black', linewidth=2)\n",
    "plt.plot(lstm_pred_dates, lstm_predictions.flatten(), label='LSTM Predictions', \n",
    "         color='red', linewidth=2, alpha=0.8)\n",
    "plt.title('LSTM VIX Predictions with Dates (Test Period)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('VIX Level')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 4: Full dataset context with predictions\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(df.index, df[target_column], label='Full VIX History', \n",
    "         color='blue', alpha=0.6, linewidth=1)\n",
    "plt.plot(lstm_pred_dates, lstm_predictions.flatten(), label='LSTM Predictions', \n",
    "         color='red', linewidth=3)\n",
    "plt.title('LSTM Predictions in Context of Full VIX History', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('VIX Level')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Prediction errors\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot error distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "errors = lstm_actuals.flatten() - lstm_predictions.flatten()\n",
    "plt.hist(errors, bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.title('Prediction Error Distribution', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot error over time\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(lstm_pred_dates, errors, color='purple', linewidth=1)\n",
    "plt.title('Prediction Error Over Time', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prediction Error')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Scatter plot: Actual vs Predicted\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(lstm_actuals.flatten(), lstm_predictions.flatten(), alpha=0.6)\n",
    "plt.plot([lstm_actuals.min(), lstm_actuals.max()], \n",
    "         [lstm_actuals.min(), lstm_actuals.max()], 'r--', linewidth=2)\n",
    "plt.title('Actual vs Predicted VIX', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Actual VIX')\n",
    "plt.ylabel('Predicted VIX')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(lstm_predictions.flatten(), errors, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.title('Residuals vs Predictions', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Predicted VIX')\n",
    "plt.ylabel('Residuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Store results for later comparison with other models\n",
    "lstm_results = {\n",
    "    'model': 'LSTM',\n",
    "    'dataset': 'VIX',\n",
    "    'mse': lstm_mse,\n",
    "    'rmse': lstm_rmse,\n",
    "    'mae': lstm_mae,\n",
    "    'mape': mape,\n",
    "    'direction_accuracy': direction_accuracy,\n",
    "    'training_time': lstm_training_time,\n",
    "    'inference_time': lstm_inference_time,\n",
    "    'predictions': lstm_predictions,\n",
    "    'actuals': lstm_actuals,\n",
    "    'prediction_dates': lstm_pred_dates,\n",
    "    'errors': errors,\n",
    "    'num_parameters': sum(p.numel() for p in lstm_model.parameters())\n",
    "}\n",
    "\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"Dataset: VIX volatility index\")\n",
    "print(f\"Training samples: {len(lstm_X_train)}\")\n",
    "print(f\"Test samples: {len(lstm_X_test)}\")\n",
    "print(f\"Sequence length: {sequence_length}\")\n",
    "print(f\"Model parameters: {lstm_results['num_parameters']}\")\n",
    "print(f\"Best metric - RMSE: {lstm_rmse:.4f}\")\n",
    "\n",
    "# Save results (optional)\n",
    "# import pickle\n",
    "# with open('lstm_vix_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(lstm_results, f)\n",
    "\n",
    "print(f\"\\nLSTM testing on VIX dataset completed successfully!\")\n",
    "print(f\"Results stored in 'lstm_results' dictionary for comparison with other models.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
