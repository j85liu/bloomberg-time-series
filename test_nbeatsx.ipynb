{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e3912c",
   "metadata": {},
   "source": [
    "## NBEATSX V3 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90c042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/b1v52j156gbfz83pmrnth3jc0000gn/T/ipykernel_84974/4129102529.py:48: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  X, Y, Exog = map(lambda x: torch.tensor(x, dtype=torch.float32), (X, Y, Exog))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NBeatsX.__init__() got an unexpected keyword argument 'forecast_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m Exog_train, Exog_test \u001b[38;5;241m=\u001b[39m Exog[:split_idx], Exog[split_idx:]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNBeatsX\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_blocks\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(model, X_train, Y_train, Exog_train, epochs, batch_size, lr):\n",
      "\u001b[0;31mTypeError\u001b[0m: NBeatsX.__init__() got an unexpected keyword argument 'forecast_size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.nbeatsx_v3 import NBeatsX  # Adjust if your filename is different\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model Parameters\n",
    "input_size = 30\n",
    "exog_size = 3\n",
    "forecast_size = 1\n",
    "hidden_units = 256\n",
    "num_blocks = 4\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create synthetic dataset\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "t = np.arange(n)\n",
    "price = 50 + 0.1 * t + 5 * np.sin(2 * np.pi * t / 50) + np.random.normal(scale=2, size=n)\n",
    "df = pd.DataFrame({\n",
    "    'Date': pd.date_range(start=\"2020-01-01\", periods=n),\n",
    "    'Price': price\n",
    "})\n",
    "\n",
    "# Data Preparation\n",
    "def prepare_data(df, input_size, exog_size):\n",
    "    prices = df[\"Price\"].values\n",
    "    dates = df[\"Date\"].values\n",
    "\n",
    "    # Generate synthetic exogenous factors\n",
    "    exog_factors = np.random.uniform(0.9, 1.1, size=(len(prices), exog_size))\n",
    "\n",
    "    X, Y, Exog = [], [], []\n",
    "    for i in range(len(prices) - input_size):\n",
    "        X.append(prices[i:i+input_size])\n",
    "        Y.append(prices[i+input_size])\n",
    "        Exog.append(exog_factors[i+input_size])\n",
    "    \n",
    "    X, Y, Exog = map(lambda x: torch.tensor(x, dtype=torch.float32), (X, Y, Exog))\n",
    "    return X, Y.unsqueeze(1), Exog\n",
    "\n",
    "X, Y, Exog = prepare_data(df, input_size, exog_size)\n",
    "\n",
    "# Train/Test split\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "Y_train, Y_test = Y[:split_idx], Y[split_idx:]\n",
    "Exog_train, Exog_test = Exog[:split_idx], Exog[split_idx:]\n",
    "\n",
    "# Model\n",
    "model = NBeatsX(\n",
    "    input_size=input_size,\n",
    "    exog_size=exog_size,\n",
    "    forecast_size=forecast_size,\n",
    "    hidden_units=hidden_units,\n",
    "    num_blocks=num_blocks\n",
    ").to(device)\n",
    "\n",
    "# Training\n",
    "def train_model(model, X_train, Y_train, Exog_train, epochs, batch_size, lr):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            x_batch = X_train[i:i+batch_size].to(device)\n",
    "            y_batch = Y_train[i:i+batch_size].to(device)\n",
    "            exog_batch = Exog_train[i:i+batch_size].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x_batch, exog_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        losses.append(epoch_loss / (len(X_train) // batch_size))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {losses[-1]:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "losses = train_model(model, X_train, Y_train, Exog_train, epochs, batch_size, learning_rate)\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_train = model(X_train.to(device), Exog_train.to(device)).cpu()\n",
    "    preds_test = model(X_test.to(device), Exog_test.to(device)).cpu()\n",
    "\n",
    "# Metrics\n",
    "def mean_scaled_absolute_error(y_true, y_pred):\n",
    "    return torch.mean(torch.abs(y_true - y_pred)) / torch.mean(torch.abs(y_true[1:] - y_true[:-1]))\n",
    "\n",
    "def relative_squared_error(y_true, y_pred):\n",
    "    return torch.sum((y_true - y_pred) ** 2) / torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "\n",
    "train_msae = mean_scaled_absolute_error(Y_train, preds_train).item()\n",
    "test_msae = mean_scaled_absolute_error(Y_test, preds_test).item()\n",
    "train_rse = relative_squared_error(Y_train, preds_train).item()\n",
    "test_rse = relative_squared_error(Y_test, preds_test).item()\n",
    "\n",
    "print(f\"\\nTrain MSAE: {train_msae:.4f}, Train RSE: {train_rse:.4f}\")\n",
    "print(f\"Test MSAE: {test_msae:.4f}, Test RSE: {test_rse:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14,6))\n",
    "full_true = torch.cat([Y_train, Y_test], dim=0).numpy()\n",
    "full_pred = torch.cat([preds_train, preds_test], dim=0).numpy()\n",
    "\n",
    "plt.plot(full_true, label=\"True Price\", color=\"black\")\n",
    "plt.plot(full_pred, label=\"Predicted Price\", color=\"blue\", alpha=0.7)\n",
    "plt.axvline(x=split_idx, color=\"red\", linestyle=\"--\", label=\"Train/Test Split\")\n",
    "plt.title(\"N-BEATSx Forecasting - True vs Predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Analyze Trend and Seasonality\n",
    "def analyze_components(model, x_sample, exog_sample):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_forecast, thetas = model(x_sample.to(device), exog_sample.to(device), return_theta=True)\n",
    "        \n",
    "        trend_forecast = torch.zeros_like(total_forecast)\n",
    "        seasonality_forecast = torch.zeros_like(total_forecast)\n",
    "        residual = x_sample.to(device)\n",
    "\n",
    "        for i, block in enumerate(model.blocks):\n",
    "            backcast, block_forecast, theta = block(residual, exog_sample.to(device))\n",
    "            residual = residual - backcast\n",
    "\n",
    "            block_type = \"Trend\" if i % 2 == 0 else \"Seasonality\"\n",
    "            print(f\"\\nBlock {i+1} ({block_type}) - Theta Sample:\")\n",
    "            print(theta[0].cpu().numpy())\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                trend_forecast += block_forecast\n",
    "            else:\n",
    "                seasonality_forecast += block_forecast\n",
    "        \n",
    "        return trend_forecast.cpu(), seasonality_forecast.cpu()\n",
    "\n",
    "# Visualize on a few test samples\n",
    "n_samples = 5\n",
    "for idx in range(n_samples):\n",
    "    trend_comp, seasonality_comp = analyze_components(\n",
    "        model, X_test[idx:idx+1], Exog_test[idx:idx+1]\n",
    "    )\n",
    "\n",
    "    true_price = Y_test[idx].item()\n",
    "    pred_price = preds_test[idx].item()\n",
    "\n",
    "    print(f\"\\nSample {idx+1}\")\n",
    "    print(f\"True Price: {true_price:.2f}, Predicted Price: {pred_price:.2f}\")\n",
    "    print(f\"Trend Contribution: {trend_comp.item():.2f}, Seasonality Contribution: {seasonality_comp.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc2506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
